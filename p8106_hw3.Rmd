---
title: "p8106 hw3"
author: "Nathalie Fadel"
date: "4/8/2019"
output: html_document
---

##Part A

###Import & view data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(caret)
library(ISLR)
library(AppliedPredictiveModeling)
library(glmnet)
library(e1071)
library(pROC)
library(MASS)
library(mlbench)
library(class)
```

```{r}
data("Weekly")

summary(Weekly)
```

###Plots
```{r}
pairs(Weekly) 

transparentTheme(trans = .4)
featurePlot(x = Weekly[, 1:8], 
            y = Weekly$Direction,
            scales = list(x=list(relation="free"), 
                        y=list(relation="free")),
            plot = "density", pch = "|", 
            auto.key = list(columns = 2))

```

##Part B

###Logistic Regression
```{r}

glm.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
               data = Weekly, 
               family = binomial)

summary(glm.fit)
```
From the glm, we can see that the only significant predictor other than the intercept term is Lag 2.  

##Part C  

###Confusion matrix  
```{r}
probs = predict(glm.fit, type = "response")
preds = rep("Down", 1089)
preds[probs > 0.5] = "Up"
table(preds, Weekly$Direction)
confusionMatrix(data = as.factor(preds), reference = Weekly$Direction, positive = "Down")
```
Based on the confusion matrix, we can see that most of the cases go up (987/1089 cases) whereas in reality there are only 605/1089 that go up. This indicates that our prediction model does not predict direction well. However, we have a large proportion of true positives (557/605 = 0.921) but this comes at a cost of finding many false positives (430/987 = 0.436).   

##Part D

###ROC curves
```{r}
test.pred.prob  <- predict(glm.fit, newdata = Weekly, type = "response")
roc.glm <- roc(Weekly$Direction, test.pred.prob)
plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm), col = 4, add = TRUE)
```  
The AUC is 0.554. 

##Part E

```{r}
training.data = Weekly[Weekly$Year < 2009,]
test.data = Weekly[Weekly$Year > 2008,]
glm.fit2 = glm(Direction ~ Lag1 + Lag2, data = training.data, family = "binomial")
summary(glm.fit2)

test.pred.prob2 <- predict(glm.fit2, newdata = test.data, type = "response")
roc.glm2 <- roc(test.data$Direction, test.pred.prob2)
plot(roc.glm2, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm2), col = 4, add = TRUE)
```
The AUC is 0.556  

##Part F

###LDA 
```{r}
lda.fit = lda(Direction ~ Lag1 + Lag2, data = training.data)
lda.fit
plot(lda.fit)

lda.pred <- predict(lda.fit, newdata = test.data)
head(lda.pred$posterior)

roc.lda <- roc(test.data$Direction, lda.pred$posterior[,2])
plot(roc.lda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.lda), col = 4, add = TRUE)
```
The AUC is 0.557.  

###QDA
```{r}
qda.fit <- qda(Direction ~ Lag1 + Lag2, data = training.data)
qda.fit

qda.pred <- predict(qda.fit, newdata = test.data)
head(qda.pred$posterior)

roc.qda <- roc(test.data$Direction, qda.pred$posterior[,2])
plot(roc.qda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.qda), col = 4, add = TRUE)
```
The AUC is 0.529.  

##Part G  

###KNN
```{r}
set.seed(1)
training.data2 = (Weekly$Year < 2009)
test.data2 = (Weekly$Year > 2008)
train.weekly = Weekly[!training.data2,2:3]
train.direction = Weekly$Direction[!training.data2]

trctrl <- trainControl(method = "repeatedcv", 
                      summaryFunction = twoClassSummary,
                      classProbs = TRUE, repeats = 5)

knn.fit <- train(x = Weekly[training.data2,2:3],
                   y = Weekly$Direction[training.data2], 
                   method = "knn",
                   preProcess = c("center","scale"),
                  tuneGrid = data.frame(k = seq(1, 50, by = 2)),
                   trControl = trctrl,
                   metric = "ROC")
knn.fit
ggplot(knn.fit)
knn.fit$bestTune

knn.predict <- predict(knn.fit, newdata = train.weekly, type = "prob")[,2]
roc.knn <- roc(train.direction, knn.predict)
plot(roc.knn, legacy.axes = TRUE, print.auc = TRUE)


```
The KNN model gives an AUC value of 0.545. The LDA model gave the highest AUC value, 0.557. Therefore it is the best model out of all that we have examined to most accurately predict true values, but it is not an ideal model, as the error rate is still quite high.
